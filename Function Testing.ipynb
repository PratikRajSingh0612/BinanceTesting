{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803035d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from binance.client import Client\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "import pandas_ta as ta\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import pytz\n",
    "import os\n",
    "# os.system('cls' if os.name == 'nt' else 'clear')\n",
    "from IPython.display import clear_output\n",
    "# clear_output(wait=True)\n",
    "\n",
    "import importlib\n",
    "import BaseFunctions\n",
    "importlib.reload(BaseFunctions)\n",
    "from BaseFunctions import *\n",
    "\n",
    "import StrategyList\n",
    "importlib.reload(StrategyList)\n",
    "from StrategyList import *\n",
    "\n",
    "import VariableCreation\n",
    "importlib.reload(VariableCreation)\n",
    "from VariableCreation import *\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Load API credentials from environment variables\n",
    "API_KEY = os.getenv(\"BinanceAPI_250502\")\n",
    "API_SECRET = os.getenv(\"BinanceSecret_250502\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "client = Client(API_KEY, API_SECRET) if API_KEY and API_SECRET else Client()\n",
    "\n",
    "BackTime = \"2024-04-01 00:00:00\"\n",
    "# Convert string to naive datetime object\n",
    "BackTime = datetime.strptime(BackTime, '%Y-%m-%d %H:%M:%S')\n",
    "# Make it timezone-aware (UTC)\n",
    "BackTime = BackTime.replace(tzinfo=timezone.utc)\n",
    "# print(BackTime)\n",
    "# BackTime = 1735689600000\n",
    "\n",
    "BackTime = int(BackTime.timestamp() * 1000)  # Convert to milliseconds\n",
    "Interval = '5m'\n",
    "current_time = time.time()\n",
    "pair = 'BTCUSDT'\n",
    "\n",
    "BuySellFlag = 'Hold'\n",
    "BuyCounter = 0\n",
    "SellCounter = 0\n",
    "\n",
    "from datetime import datetime; import pytz; epoch_to_utc = lambda epoch: datetime.fromtimestamp(epoch / 1000.0 if epoch > 1e10 else epoch, tz=pytz.UTC).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4786c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = int(time.time() * 1000)  # Current time in ms\n",
    "interval_ms = 5 * 60 * 1000  # 5 minutes in ms\n",
    "\n",
    "# 2. Chunking logic for END-TIME based requests\n",
    "time_chunks = []\n",
    "current_end = BackTime + (1000 * interval_ms)  # First chunk ends after 1000 candles\n",
    "\n",
    "while current_end <= current_time:\n",
    "    time_chunks.append(current_end)\n",
    "    current_end += 1000 * interval_ms  # Move window forward\n",
    "    \n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "df2 = pd.DataFrame()\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Submit tasks to the executor\n",
    "    futures = [executor.submit(get_candles_data, pair, Interval, 1000, end, client) for end in time_chunks]\n",
    "    \n",
    "    # Process results as they complete\n",
    "    for future in as_completed(futures):\n",
    "        df1 = future.result()\n",
    "        if not df1.empty:\n",
    "            df2 = pd.concat([df2, df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_counts = df2['Open Time'].value_counts()\n",
    "print(time_counts[time_counts > 1])\n",
    "\n",
    "print(df2['Open Time'].min())\n",
    "\n",
    "print(df2['Open Time'].max())\n",
    "\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores_mp = multiprocessing.cpu_count()\n",
    "\n",
    "def process_time(current_time, df2, pair, client):\n",
    "    \"\"\"Processes a single timestamp and returns the result.\"\"\"\n",
    "    try:\n",
    "        # Get only NEW data since last iteration\n",
    "        new_data = df2[df2['epochTime'] == current_time]\n",
    "        window_data = pd.concat([df2[df2['epochTime'] < current_time], new_data])\n",
    "        # Clear the console at the start of each iteration\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Process only when we have sufficient history\n",
    "        if len(window_data) > 100:  # Minimum window size\n",
    "            processed = create_variablesV2(window_data.copy(), pair, client, current_time)\n",
    "            strategized = allstrategiesv2(processed)\n",
    "            \n",
    "            # Return only the latest result to save memory\n",
    "            if not strategized.empty:\n",
    "                return strategized.iloc[[-1]]  # Only keep last row\n",
    "    except Exception as e:\n",
    "        print(f\"Error at {current_time}: {str(e)}\")\n",
    "    return None\n",
    "\n",
    "def parallel_process(df2, pair, client):\n",
    "    \"\"\"Processes all timestamps in parallel.\"\"\"\n",
    "    # Convert timestamps once\n",
    "    df2['Close Time'] = pd.to_datetime(df2['Close Time'])\n",
    "    df2['epochTime'] = (df2['Close Time'].astype('int64') // 10**6)\n",
    "    \n",
    "    # Sort by time and get unique epochs\n",
    "    df2 = df2.sort_values('epochTime')\n",
    "    unique_times = df2['epochTime'].unique()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=cores_mp) as executor:  # Limit to 10 threads\n",
    "        # Submit tasks to the executor\n",
    "        futures = [executor.submit(process_time, current_time, df2, pair, client) for current_time in unique_times]\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in tqdm(as_completed(futures), total=len(unique_times), desc=\"Processing\"):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "                \n",
    "                # Optional: Clear memory periodically\n",
    "                if len(results) % 1000 == 0:\n",
    "                    pd.concat(results).to_parquet(f\"partial_{len(results)}.parquet\")\n",
    "                    results = []\n",
    "                \n",
    "    \n",
    "    # Final concatenation\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "# Example usage\n",
    "final_df = parallel_process(df2, pair, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007df2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('BTCUSDT2024Onwards_AllVarsAndStats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ce00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps once\n",
    "df2['Close Time'] = pd.to_datetime(df2['Close Time'])\n",
    "df2['epochTime'] = (df2['Close Time'].astype('int64') // 10**6)\n",
    "\n",
    "# Sort by time and get unique epochs\n",
    "df2 = df2.sort_values('epochTime')\n",
    "unique_times = df2['epochTime'].unique()\n",
    "\n",
    "# Pre-allocate results list instead of growing DataFrame\n",
    "results = []\n",
    "window_data = pd.DataFrame()\n",
    "\n",
    "for current_time in tqdm(unique_times, desc=\"Processing\"):\n",
    "    try:\n",
    "        # Get only NEW data since last iteration (much more efficient)\n",
    "        new_data = df2[df2['epochTime'] == current_time]\n",
    "        window_data = pd.concat([window_data, new_data])\n",
    "        \n",
    "        # Process only when we have sufficient history\n",
    "        if len(window_data) > 100:  # Minimum window size\n",
    "            processed = create_variablesV2(window_data.copy(), pair, client, current_time)\n",
    "            strategized = allstrategiesv2(processed)\n",
    "            \n",
    "            # Append only the latest result to save memory\n",
    "            if not strategized.empty:\n",
    "                results.append(strategized.iloc[[-1]])  # Only keep last row\n",
    "                \n",
    "        # Optional: Clear memory periodically\n",
    "        if len(results) % 1000 == 0:\n",
    "            pd.concat(results).to_parquet(f\"partial_{current_time}.parquet\")\n",
    "            results = []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error at {current_time}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Final concatenation\n",
    "final_df = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ffba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
